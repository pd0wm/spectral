
\documentclass[report, oneside, a4paper, openany]{memoir}
\input{../../includes/preamble.tex}

\title{Documentation}

\author{W.P. Bruinsma \and R.P. Hes \and H.J.C. Kroep \and T.C. Leliveld \and W.M. Melching \and T.A. aan de Wiel}

\begin{document}
\chapter{Reconstruction}
The reconstruction uses the output of the sampling block to estimate the power spectral density.

\section{Multicoset Sampling Reconstruction -Time-Domain Approach}
\subsection{Concept}
We want to estimate the PSD of a signal $x[n]$, but we want to achieve this with a sampling-rate that is significantly lower than Nyquist. 
This method uses multiple devices to achieve this. 
We want to get a system of linear equations with more equations than variables so that we can solve it with the Least Squares (LS) method. 
If we sample down with a factor $N$ we need $N$ lineary independent equations to use LS.
This reconstruction method uses the cross-correlation of the different devices to get these equations. It allows you to get $M^2$ different equations with $M$ being the amount of devices used.\\
\\
The acquiring of samples is handled in the section about Sampling. It is the job of the Sampling block to deliver a set of sampled signals of the form 
$$y_l[k] = z_l[kN] \quad l \in \{0,1,\dots, M-1\}$$
Where
\begin{itemize}
\item $M$  = amount of sampling devices
\item $N = \frac{\text{Nyquist rate}}{\text{Sample Frequency}}$
\item $k$ = the sampling index
\item $z[k]$ = sampled signal if on Nyquist
\item $y[k]$ = sampled signal on actual sample rate
\end{itemize}

Note that $y_l[k]$ is acquired in the Sampling method using
\begin{equation*}
\begin{split}
z_l[n] &= c_l[n]\ast x[n]\\
y_l[k] &= \frac{1}{NT}\int_{kNT}^{(k+1)NT} z_l[n]
\end{split}
\end{equation*}
Note that $c[n]$ could be anything, but this is discussed further in the Sampling section.\\
\\
Now there are three different methods proposed to reconstruct the Power Spectral Density (PSD) of $x[n]$. 
However, the first method is the most convenient for our application. 
Therefore we will focus on the time-domain reconstruction method.

\subsubsection{Theory}
We want to estimate $r_x[n]$, the auto correlation of $x[n]$, because this contains enough information to determine the PSD.
We want to pick the $M$ different device measurements, combine these into $M^2$ different cross-correlation functions and use these to reconstruct the auto-correlation with a sampling that is $N$ lower than nyquist. 
This is only possible when $M^2>N$. We want to get an expression of the form
$$
\mathbf{r}_y = \mathbf{R}_c\mathbf{r}_x
$$ 
Where
\begin{itemize}
\item $\mathbf{r}_y$ represents the auto-correlations of the different measurement devices
\item $\mathbf{R}_c$ represents the cross-correlations of the different measurement devices 
\item $\mathbf{r}_x$ represents the auto-correlation of the original signal
\end{itemize}
If we would be able to define the variables in this equation we can solve our system with LS.\\
\\
We start of with the auto-correlation of the different devices.

$$
r_{yi,yj}[k] = r_{zi,zj}[kN]
$$
here $r_{yi,yj}[k]$ is the cross-correlation function of $y_i[k]$ and $y_j[k]$.
$$
r_{yi,yj}[k] = r_{zi,zj}[kN] = \sum_{m=-N+1}^{N-1}r_{ci,cj}[m]r_x[kN-m] = \sum_{l=0}^1\mathbf{r}^T_{ci,cj}[l]\mathbf{r}_x[k-l]
$$
This is basically a rewrite with new defined variables. Note that $l \in \{0,1\}$. $\mathbf{r}_{ci,cj}[0]$ is the part where $m\leq 0$ and $\mathbf{r}_{ci,cj}[1]$ is the part where $m > 0$ 
$$
\mathbf{r}_{ci,cj}[l] = [r_{ci,cj}[Nl], r_{ci,cj}[Nl-1], \dots, r_{ci,cj}[Nl-N+1]]^T
$$
$$
\mathbf{r}_x[k]= [r_x[kN],r_x[kN+1],\dots,r_x[(k+1)N-1]]^T
$$
Note that $\mathbf{r}_x[k]$ is the auto-correlation function we want to get. 
Because $y_l[k]$ has $N$ times less samples than the original $x[n]$, we need an $\mathbf{r}_x$ of size $N \times 1$.
This vector $\mathbf{r}_x[k]$ basically contains the $N$ variables we want to solve with the $M^2$ equations.

Now we make a vector $\mathbf{r}_y[k]$ by combining every possible combination of the $M$ devices into $M^2$ cross-correlations. $\mathbf{r}_y[k]$ is basically a vector containing all available $\mathbf{r}_{yi,yj}[k]$
$$
\mathbf{r}_y[k]=\sum_{l=0}^1\mathbf{R}_c[l]\mathbf{r}_x[k-l]
$$
Again note that $l \in \{0,1\}$ and that $l=0$ covers $m\leq 0$ and $l=1$ covers $m > 0$. $\mathbf{R}_c$ is an $M^2 \times N \times 2$ matrix.
$$
\mathbf{R}_c[l] = [\dots,\mathbf{r}_{ci,cj}[l],\dots]^T \quad l \in \{0,1\}, i,j \in \{0,1, \dots, M-1\}
$$
Note that every element $\mathbf{r}_{ci,cj}[l]$ of $\mathbf{R}_c[l]$ is a vector of $N \times 1$! $\mathbf{R}_c[l]$ is therefore a matrix with elements that are time dependent.\\
\\
Next up we introduce a new variable $L$. This is the amount of samples of $y[k]$ that we use to determine the PSD. This value can be choosen freely, 
but has influence on the accuracy and the processing cost of the algoritm. 
Note that the cross-correlation between two samples of length $L$ has a length of $2L+1$. 
Because of this, we only need to calculate $\mathbf{r}_x[k]$ for $-L<k\leq L$. 
We can use this to pick $\mathbf{r}_y[k]$ and $\mathbf{r}_x[k]$, and put them into two big vectors.
$$
\mathbf{r}_y = [\mathbf{r}^T_y[0],\mathbf{r}^T_y[1],\dots,\mathbf{r}^T_y[L],\mathbf{r}^T_y[-L],\dots,\mathbf{r}^T_y[-1]]^T
$$
$$
\mathbf{r}_x = [\mathbf{r}^T_x[0],\mathbf{r}^T_x[1],\dots,\mathbf{r}^T_x[L],\mathbf{r}^T_x[-L],\dots,\mathbf{r}^T_x[-1]]^T
$$
where $\mathbf{r}_y$ has size $(2L+1)M^2\times 1$ and $\mathbf{r}_x$ has size $(2L+1)N \times 1$. \\

After this batch of new definitions and variables we finally arrive at the key point of the previous math:
$$
\mathbf{r}_y = \mathbf{R}_c\mathbf{r}_x
$$ 
Where
\begin{itemize}
\item $\mathbf{r}_y$ represents the auto-correlations of the different measurement devices
\item $\mathbf{R}_c$ represents the cross-correlations of the different measurement devices 
\item $\mathbf{r}_x$ represents the auto-correlation of the original signal
\end{itemize}
This equation is solvable for $\mathbf{r}_x$ if $M^2\geq N$. So, if you are able to construct the elements in the equations above, you can use LS to estimate $\mathbf{r}_x$, the auto-correlation of the original $x[n]$ signal.\\
Now we apply the LS. We use
\begin{equation*}
\begin{split}
\mathbf{q}_x &= (\mathbf{F}_{2L+1}\otimes \mathbf{I}_N)\mathbf{r}_x \\
\mathbf{q}_y &= (\mathbf{F}_{2L+1}\otimes \mathbf{I}_M)\mathbf{r}_y \\
\mathbf{Q}_c[\omega] &= \sum_{k=0}^1\mathbf{R}_c[k]e^{-jk\omega}
\end{split}
\end{equation*}
Here $\mathbf{Q}_c$ is a diagonalisation of $\mathbf{R}_c$. We use this to rewrite our equation
$$
\mathbf{q}_y = \mathbf{Q}_c\mathbf{q}_x
$$
This is enough to calculate $\mathbf{r}_x$. Finally we calculate the PSD with
$$
\mathbf{s}_x = \mathbf{F}_{(2L+1)N}\mathbf{r}_x
$$ 



\subsection{Implementation}

\subsection{Verification}

\end{document}
