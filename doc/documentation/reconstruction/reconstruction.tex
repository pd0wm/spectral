
\documentclass[report, oneside, a4paper, openany]{memoir}
\input{../../includes/preamble.tex}

\title{Documentation}

\author{W.P. Bruinsma \and R.P. Hes \and H.J.C. Kroep \and T.C. Leliveld \and W.M. Melching \and T.A. aan de Wiel}

\begin{document}
\chapter{Reconstruction}
The reconstruction uses the output of the sampling block to estimate the power spectral density.

\section{Multi-coset Sampling Reconstruction -Time-Domain Approach}
We want to estimate the PSD of a signal $x[n]$, but we want to achieve this with a sampling-rate that is a factor $N$ lower than Nyquist. We want to get a system of linear equations with $\text{equation}\geq \text{variables}$, to solve it with the Least-squares method (LS). This reconstruction method uses the cross-correlation of $M$ different devices to achieve this. 
It allows you to get $M^2$ different equations (all the cross-correlation combinations of the $M$ devices). This method only works when $M^2\geq N$\\
\\
The acquisition of samples is handled in the section about Sampling. It is the job of the Sampling block to deliver a set of sampled signals of the form 
$$y_l[k] = z_l[kN] \quad l \in \{0,1,\dots, M-1\}$$
Where
\begin{itemize}
\item $M$  = amount of sampling devices
\item $N = \frac{\text{Nyquist rate}}{\text{Sampling Frequency}} = $ the decimation factor
\item $k$ = the sampling index
\item $z[k]$ = sampled signal if on Nyquist
\item $y[k]$ = sampled signal on actual sample rate
\end{itemize}

Note that $y_l[k]$ is acquired in the Sampling method using
\begin{align}
z_l[n] &= c_l[n]\ast x[n]\\
y_l[k] &= \frac{1}{NT}\int_{kNT}^{(k+1)NT} z_l[n]
\end{align}
Note that $c_l[n]$ is a set of filters. We previously saw that this is f the form 
$$
c_l[n] = \delta[-n -n_l]
$$
Now there are three different methods proposed to reconstruct the Power Spectral Density (PSD) of $x[n]$. 
However, the first method is the most convenient for our application. 
Therefore we will focus on the time-domain reconstruction method.

\subsubsection{Theory}
We want to estimate $r_x[n]$, the auto correlation of $x[n]$, because this contains enough information to determine the PSD.
Recall that the samples signals are $N$ times decimated, so in order to estimate the auto-correlation of the original signal we need to get at least $N$ equations. 
We want an expression of the form
$$
\mathbf{r}_y = \mathbf{R}_c\mathbf{r}_x
$$ 
Where
\begin{itemize}
\item $\mathbf{r}_y$ represents the auto-correlations of the signals of the different measurement devices
\item $\mathbf{R}_c$ represents the cross-correlations of the signals of the different measurement devices 
\item $\mathbf{r}_x$ represents the auto-correlation of the original signal
\end{itemize}
If we would be able to define the variables in this equation we can solve our system with LS.\\
\\
We start of with the auto-correlation of the different devices.

$$
r_{yi,yj}[k] = r_{zi,zj}[kN]
$$
here $r_{yi,yj}[k]$ is the cross-correlation function of $y_i[k]$ and $y_j[k]$.
We define $r_{ci,cj}$ as the cross-correlation of the different filers $c_l[n]$.
Recall that 
$$
z_l[n] = c_l[n]\ast x[n]
$$
Therefore we can write
$$
r_{yi,yj}[k] = r_{zi,zj}[kN] = \sum_{m=-N+1}^{N-1}r_{ci,cj}[m]r_x[kN-m] = \sum_{l=0}^1\mathbf{r}^T_{ci,cj}[l]\mathbf{r}_x[k-l]
$$
This is basically a rewrite with new defined variables. Note that $l \in \{0,1\}$. $\mathbf{r}_{ci,cj}[0]$ is the part where $m\leq 0$ and $\mathbf{r}_{ci,cj}[1]$ is the part where $m > 0$ 
$$
\mathbf{r}_{ci,cj}[l] = [r_{ci,cj}[Nl], r_{ci,cj}[Nl-1], \dots, r_{ci,cj}[Nl-N+1]]^T
$$
$$
\mathbf{r}_x[k]= [r_x[kN],r_x[kN+1],\dots,r_x[(k+1)N-1]]^T
$$
Recall that $\mathbf{r}_x[k]$ is the auto-correlation function we want to get and that it contains the $N$ variables we want to estimate.\\
\\
Now we make a vector $\mathbf{r}_y[k]$ by combining every possible combination of the $M$ devices into $M^2$ cross-correlations. $\mathbf{r}_y[k]$ is basically a vector containing all available $\mathbf{r}_{yi,yj}[k]$
$$
\mathbf{r}_y[k]=\sum_{l=0}^1\mathbf{R}_c[l]\mathbf{r}_x[k-l]
$$
Again note that $l \in \{0,1\}$ and that $l=0$ covers $m\leq 0$ and $l=1$ covers $m > 0$. $\mathbf{R}_c$ is an $M^2 \times N \times 2$ matrix.
$$
\mathbf{R}_c[l] = [\dots,\mathbf{r}_{ci,cj}[l],\dots]^T \quad l \in \{0,1\}, i,j \in \{0,1, \dots, M-1\}
$$
Note that every element $\mathbf{r}_{ci,cj}[l]$ of $\mathbf{R}_c[l]$ is a vector of $N \times 1$. $\mathbf{R}_c[l]$ is therefore a matrix with elements that are time dependent.\\
\\
Next up we introduce a new variable $L$. we use this to determine the range of k: $-L\leq k<L$. 
This value can be choosen freely, but has influence on the accuracy and the processing cost of the algoritm. 
Note that the amount of values of $k$ is $2L+1$. We can use this to pick $\mathbf{r}_y[k]$ and $\mathbf{r}_x[k]$, and put them into two big vectors.
$$
\mathbf{r}_y = [\mathbf{r}^T_y[0],\mathbf{r}^T_y[1],\dots,\mathbf{r}^T_y[L],\mathbf{r}^T_y[-L],\dots,\mathbf{r}^T_y[-1]]^T
$$
$$
\mathbf{r}_x = [\mathbf{r}^T_x[0],\mathbf{r}^T_x[1],\dots,\mathbf{r}^T_x[L],\mathbf{r}^T_x[-L],\dots,\mathbf{r}^T_x[-1]]^T
$$
where $\mathbf{r}_y$ has size $(2L+1)M^2\times 1$ and $\mathbf{r}_x$ has size $(2L+1)N \times 1$. \\

After this batch of new definitions and variables we finally arrive at the key point of the previous math:
$$
\mathbf{r}_y = \mathbf{R}_c\mathbf{r}_x
$$ 
Where
\begin{itemize}
\item $\mathbf{r}_y$ represents the auto-correlations of the different measurement devices
\item $\mathbf{R}_c$ represents the cross-correlations of the different measurement devices 
\item $\mathbf{r}_x$ represents the auto-correlation of the original signal
\end{itemize}
If you are able to construct the elements in the equations above, and $\mathbf{r}_y$ has more elements than $\mathbf{r}_x$, you can use LS to estimate $\mathbf{r}_x$, the auto-correlation of the original $x[n]$ signal.\\
Now we apply the LS. We use
\begin{align}
\mathbf{q}_x &= (\mathbf{F}_{2L+1}\otimes \mathbf{I}_N)\mathbf{r}_x \\
\mathbf{q}_y &= (\mathbf{F}_{2L+1}\otimes \mathbf{I}_M)\mathbf{r}_y \\
\mathbf{Q}_c[\omega] &= \sum_{k=0}^1\mathbf{R}_c[k]e^{-jk\omega}
\end{align}
Here $\mathbf{Q}_c$ is a diagonalisation of $\mathbf{R}_c$. $F$ is the DFT matrix. 
We use this to rewrite the equation into
$$
\mathbf{q}_y = \mathbf{Q}_c\mathbf{q}_x
$$
This is enough to calculate $\mathbf{r}_x$. Finally we calculate the PSD $s_x$ with
$$
\mathbf{s}_x = \mathbf{F}_{(2L+1)N}\mathbf{r}_x
$$ 

\subsection{Implementation}

\subsection{Verification}

\end{document}
