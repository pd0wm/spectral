%!TEX program = xelatex

\documentclass[a4paper, openany, oneside]{memoir}
\input{../includes/preamble.tex}
\addbibresource{../includes/bibliography.bib}

\title{Thesis}

\author{W.P. Bruinsma \and R.P. Hes \and H.J.C. Kroep \and T.C. Leliveld \and W.M. Melching \and T.A. aan de Wiel}

\raggedbottom

\begin{document}
\frontmatter

\begin{titlingpage}
  \pagestyle{empty}
  \maketitle
\end{titlingpage}

\chapter{Reconstruction}
Let the input signal be denoted by $\vec{x} \in \mathbb{R}^{LN}$. Consider $\vec{c}_i \in \mathbb{R}^{N}$ for $i = 1,\ldots,M$.

\begin{definition}[Convolution]
    Let $\vec{x} \in \mathbb{R}^N$ and $\vec{y} \in \mathbb{R}^M$. Then $\vec{x} \ast \vec{y}$ denotes a vector $\vec{z} \in \mathbb{R}^{N+M-1}$ such that
    \begin{align*}
        (\vec{z})_i = \sum_{k=1}^{N} (\vec{x})_k (\vec{y})_{i-k+1}
    \end{align*}
    where $(\vec{x})_i=0$ for $i < 1$ and $i > N$ and $(\vec{y})_i=0$ for $i < 1$ and $i > M$.
\end{definition}

\begin{theorem}[Commutativity of Convolution]
    Let $\vec{x} \in \mathbb{R}^N$ and $\vec{y} \in \mathbb{R}^M$. Then $\vec{x} \ast \vec{y} = \vec{y} \ast \vec{x}$.
\end{theorem}
\begin{proof}
    A change of index yields that
    \begin{align*}
        (\vec{x} \ast \vec{y})_i &= \sum_{k=1}^{N} (\vec{x})_k (\vec{y})_{i-k+1} \\
        &= \sum_{k=-\infty}^{\infty} (\vec{x})_k (\vec{y})_{i-k+1} \\
        &= \sum_{k'=-\infty}^{\infty} (\vec{y})_{k'} (\vec{x})_{i-k'+1} \\
        &= \sum_{k'=1}^{M} (\vec{y})_{k'} (\vec{x})_{i-k'+1} \\
        &= (\vec{y} \ast \vec{x})_i.
    \end{align*}
\end{proof}

\begin{definition}[Correlation]
    Let $\vec{x} \in \mathbb{R}^N$ and $\vec{y} \in \mathbb{R}^M$. Then $\vec{x} \circ \vec{y}$ denotes a vector $\vec{z} \in \mathbb{R}^{N+M-1}$ such that
    \begin{align*}
        (\vec{z})_i = \sum_{k=1}^{N} (\vec{x})_k (\vec{y})_{M-i+k}
    \end{align*}
    where $(\vec{x})_i=0$ for $i < 1$ and $i > N$ and $(\vec{y})_i=0$ for $i < 1$ and $i > M$.
\end{definition}

Let $\vec{y}_i = \vec{c}_i \ast \vec{x}$ for $i = 1,\ldots,M$.

\begin{theorem}
    \begin{align*}
        \vec{y}_i \circ \vec{y}_j = (\vec{c}_i \circ \vec{c}_j) \ast (\vec{x} \circ \vec{x}).
    \end{align*}
\end{theorem}
\begin{proof}
    Note that
    \begin{align*}
        (\vec{y}_i \circ \vec{y}_j)_m
        &= [(\vec{c}_i \ast \vec{x}) \circ (\vec{c}_j \ast \vec{x})]_m \\
        &=\sum_{k''=1}^{LN+N-1}\sum_{k=1}^N (\vec{c}_i)_k (\vec{x})_{k''-k+1}\sum_{k'=1}^{N}(\vec{c}_j)_{k'}(\vec{x})_{(LN+N-1-m+k'')-k'+1} \\
        &=\sum_{k=-\infty}^\infty\sum_{k'=\infty}^{\infty}\sum_{k''=-\infty}^{\infty} (\vec{c}_i)_k (\vec{c}_j)_{k'}(\vec{x})_{k''-k+1}(\vec{x})_{(LN+N-1-m+k'')-k'+1}.
    \end{align*}
    To further evaluate this expression, we introduce a change of variables. To this end, let $k' = N -l'' +k$ and $k'' = l' + k - 1$. This transformation is invertible, so
    \begin{align*}
        (\vec{y}_i \circ \vec{y}_j)_m
        % I don't think this step is necessary
        % &=\sum_{k=-\infty}^\infty\sum_{l''=-\infty}^{\infty}\sum_{l'=\infty}^{\infty} (\vec{c}_i)_k (\vec{c}_j)_{N -l'' +k}(\vec{x})_{(l' + k - 1)-k+1}(\vec{x})_{[LN+N-1-m+(l' + k - 1)]-(N -l'' +k)+1} \\
        &=\sum_{k=-\infty}^\infty\sum_{l''=-\infty}^{\infty}\sum_{l'=\infty}^{\infty} (\vec{c}_i)_k (\vec{c}_j)_{N -l'' +k}(\vec{x})_{l'}
        (\vec{x})_{LN-(m-l'' + 1)+l'} \\
        &=\sum_{l''=1}^{2N-1}\sum_{k=1}^{N}(\vec{c}_i)_k (\vec{c}_j)_{N -l'' +k}\sum_{l'=1}^{LN}(\vec{x})_{l'}
        (\vec{x})_{LN-(m-l'' + 1)+l'} \\
        % &=\sum_{k''=1}^{2N-1} \sum_{k=1}^{N} (\vec{c}_i)_k (\vec{c}_j)_{N-k''+k} \sum_{k'=1}^{LN} (\vec{x})_{k'} (\vec{x})_{LN-(m-k''+1)+k'} \\
        &=[(\vec{c}_i \circ \vec{c}_j) \ast (\vec{x} \circ \vec{x})]_m.
    \end{align*}
\end{proof}

We denote 
\begin{align*}
    \vec{r}_{y_i,y_j} = \vec{y}_i \circ \vec{y}_j = (\vec{c}_i \circ \vec{c}_j) \ast (\vec{x} \circ \vec{x}) = \vec{r}_{c_i,c_j} \ast \vec{r}_x.
\end{align*}
Using commutativity and the definition of the convolution operator, we can write this equation as
\begin{align*}
    \vec{r}_{y_i,y_j} &=  \vec{r}_{c_i,c_j} \ast \vec{r}_x \\
    &= \vec{r}_x \ast \vec{r}_{c_i,c_j} \\
    &= \begin{bmatrix}
        (\vec{r}_{c_i,c_j})_1 & 0 & 0& \cdots & & &  0 \\
        (\vec{r}_{c_i,c_j})_2 & (\vec{r}_{c_i,c_j})_1 & 0 & \cdots & & & 0 \\
        \vdots &  & & \ddots & &  & \vdots\\
        \cdots & (\vec{r}_{c_i,c_j})_{2N-1} & (\vec{r}_{c_i,c_j})_{2N-2} & \cdots & (\vec{r}_{c_i,c_j})_2 & (\vec{r}_{c_i,c_j})_1 & 0 \\
        \cdots & 0 & (\vec{r}_{c_i,c_j})_{2N-1} & \cdots & (\vec{r}_{c_i,c_j})_3 & (\vec{r}_{c_i,c_j})_2 & (\vec{r}_{c_i,c_j})_1 \\
    \end{bmatrix} \begin{bmatrix}
        (\vec{r}_x)_1 \\
        (\vec{r}_x)_2 \\
        \vdots \\
        (\vec{r}_x)_{2LN-2} \\
        (\vec{r}_x)_{2LN-1}
    \end{bmatrix} \\
    &= \mat{R}_{c_i,c_j} \vec{r}_x.
\end{align*}
Let the $L \times NL$ decimation matrix be defined by $(\mat{D})_{i(Ni)} = 1$ for $i=1,\ldots,L$ and otherwise zero. Then let $\vec{r}_y$ and $\mat{R}$ be such that
\begin{align*}
    \begin{bmatrix}
        \mat{D}\vec{r}_{y_1,y_1} \\
        \vdots \\
        \mat{D}\vec{r}_{y_M,y_M}
    \end{bmatrix}
    = \begin{bmatrix}
        \vec{r}_{y'_1,y'_1} \\
        \vdots \\
        \vec{r}_{y'_M,y'_M}
    \end{bmatrix}
    = \vec{r}_y
    = \begin{bmatrix}
        \mat{D}\mat{R}_{c_1,c_1} \vec{r}_x \\
        \vdots \\
        \mat{D}\mat{R}_{c_M,c_M} \vec{r}_x
    \end{bmatrix}
    = \begin{bmatrix}
        \mat{D}\mat{R}_{c_1,c_1}\\
        \vdots \\
        \mat{D}\mat{R}_{c_M,c_M}
    \end{bmatrix} \vec{r}_x
    = \mat{R} \vec{r}_x.
\end{align*}
Thus $\mat{R}$ relates $\vec{r}_y$ and $\vec{r}_x$. We now investigate $\vec{r}_{y'_i,y'_j}$'s structure. Notice that
\begin{align*}
    \vec{r}_{y'_i,y'_j}
    = \begin{bmatrix}
        (\vec{r}_{y'_i,y'_j})_1 \\
        (\vec{r}_{y'_i,y'_j})_2 \\
        \vdots \\
        (\vec{r}_{y'_i,y'_j})_{L} \\
    \end{bmatrix}
    = \begin{bmatrix}
        (\vec{r}_{y_i,y_j})_{N} \\
        (\vec{r}_{y_i,y_j})_{2N} \\
        \vdots \\
        (\vec{r}_{y_i,y_j})_{NL} \\
    \end{bmatrix}
    = \begin{bmatrix}
        (\vec{r}_{y_i,y_j})_{N} \\
        (\vec{r}_{y_i,y_j})_{2N} \\
        \vdots \\
        (\vec{r}_{y_i,y_j})_{NL} \\
    \end{bmatrix}.
\end{align*}
Thus $\vec{r}_{y'_i,y'_j}$ is a $N$-decimation of $\vec{r}_{y_i,y_j}$. It can be shown that is equivalent to correlation of the $N$-decimation between
\end{document}
