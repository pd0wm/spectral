
\documentclass[report, oneside, a4paper, openany]{memoir}
\input{../../includes/preamble.tex}

\title{Documentation}

\author{W.P. Bruinsma \and R.P. Hes \and H.J.C. Kroep \and T.C. Leliveld \and W.M. Melching \and T.A. aan de Wiel}

\begin{document}
\chapter{Reconstruction}
The reconstruction uses the output of the sampling block to estimate the power spectral density.

\section{Multicoset Sampling Reconstruction -Ariananda}
\subsection{Concept}
The expected input of this reconstruction method is a multicoset sampled signal of the form:
$$
\sum_{l=0}^{M-1}z_l[kN]
$$
Where
\begin{itemize}
\item $M$  = amount of sampling devices
\item $N = \frac{\text{sample frequency}}{\text{nyquist rate}}$
\item $k$ = the sampling index.
\end{itemize}

Now there are three different methods proposed to reconstruct the Power Spectral Density (PSD) of $x[n]$.

\subsubsection{Time-Domain Reconstruction Approach}
We desire to reconstruct $r_x[n]$, the auto correlation of $x[n]$, for this holds enough information to determine the PSD.
We want to pick the $M$ different measurement device outputs, combine these into $M^2$ different cross-correlation functions and use these to reconstruct the auto-correlation with a sampling that is $N$ lower than nyquist. Thisn is only possible when $M^2>N$.

For example: if  one would use 10 different measurement devices, one would theoretically be able to reconstruct a PSD with a sampling rate that is 100 times less than nyquist! This would however require a lot of processing power, which limits the application of this algoritm.
$$
r_{yi,yj}[k] = r_{zi,zj}[kN]
$$
where $r_{yi,yj}[k]$ is the cross-corelation function of $y_i[k]$ and $y_j[k]$.
$z[n]$ is the signal we would have got if we sampled on nyquist frequency. Therefore $z[n]$ has N times more samples than $y[n]$.
$$
r_{yi,yj}[k] = r_{zi,zj}[kN] = \sum_{m=-N+1}^{N-1}r_{ci,cj}[m]r_x[kN-m] = \sum_{l=0}^1\mathbf{r}^T_{ci,cj}[l]\mathbf{r}_x[k-l]
$$
This is basically a rewrite with new defined variables. Note that $l$ is a boolean here. $\mathbf{r}_{ci,cj}[0]$ is the part where $m\leq 0$ and $\mathbf{r}_{ci,cj}[1]$ is the part where $m > 0$ 
$$
\mathbf{r}_{ci,cj}[l] = [r_{ci,cj}[Nl], r_{ci,cj}[Nl-1], \dots, r_{ci,cj}[Nl-N+1]]^T
$$
$$
\mathbf{r}_x[k]= [r_x[kN],r_x[kN+1],\dots,r_x[(k+1)N-1]]^T
$$
Note that $\mathbf{r}_t[k]$ is the auto-correlation function we want to get, consisting of N parts. Recall that we need N parts because we want to sample at a rate N times less than nyquist ratre.\\
\\
Now we make a vector $\mathbf{r}_y[k]$ by combining every possible combination of the $M$ auto-correlations into $M^2$ cross-correlations. $\mathbf{r}_y[k]$ is basically a vector containing all available $\mathbf{r}_{yi,yj}[k]$
$$
\mathbf{r}_y[k]=\sum_{l=0}^1\mathbf{R}_c[l]\mathbf{r}_x[k-l]
$$
Again recall that $l$ is a boolean and that $l=0$ covers $m\leq 0$ and $l=1$ covers $m > 0$. $\mathbf{R}_c$ is an $M^2 \times N \times 2$ matrix.
$$
\mathbf{R}_c[l] = [\dots,\mathbf{r}_{ci,cj}[l],\dots]^T \quad l \in \{0,1\}, i,j \in \{0,1, \dots, M-1\}
$$
Note that $\mathbf{r}_{ci,cj}[l]$ is a matrix of $N \times 2$! $\mathbf{R}_c[l]$ is therefore a matrix with elements that are time dependent.





\subsection{implementation}

\subsection{verification}

\end{document}
