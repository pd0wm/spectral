%!TEX program = xelatex

\documentclass[a4paper, openany, oneside]{memoir}
\input{../../../includes/preamble.tex}
\addbibresource{../../../includes/bibliography.bib}

\title{Compressive Sensing - An Overview}

\author{W.P. Bruinsma \and R.P. Hes \and H.J.C. Kroep \and T.C. Leliveld \and W.M. Melching \and T.A. aan de Wiel}

\raggedbottom

\begin{document}
\chapter{Model - The Core}
\label{cha:model}
In this chapter we will discuss the model part of our system. This consists of the various implementations of source, sampling, reconstruction and detection components. All functionality discussed in this chapter is contained in the \lib{spectral.core} sub-package. \Cref{fig:model-diagram} shows the model and its interfaces. Every interface sets up a contract for one or more methods, which mean any class that implements this interface must also implement the method.

\begin{figure}
    \centering
    \begin{adjustbox}{width=\textwidth}
    \input{./figures/model-diagram}
    \end{adjustbox}
    \caption{The model and its interfaces}
    \label{fig:model-diagram}
\end{figure}

\section{Source}
\label{sec:source}
All sources implement the interface \func{Source}, which has a contract for a generate method. This generate function should return the requested number of samples from a specific source. The sources can be divided in three categories, the simulated sources used for testing our algorithms, the file sources which generate data from saved files and real-world sources that connect to the USRPs to retrieve samples.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/classes_source.eps}
    \caption{The UML diagram of the sources}
    \label{fig:umlsource}
\end{figure}

\subsection{Simulated Source}
\label{sec:simulated-source}
The simulated sources are used for testing our algorithms. All the simulated sources have the same base class, \func{SimulatedSource}. This base class adds some utility methods to the sources to add Gaussian noise to the generated data.

\subsubsection{Sinusoidal}
The sinusoidal source generates a real valued signal, with a sum of real valued sinusoidal signals with different frequencies. Because the signal is real valued this generates a symmetrical spectrum. Optionally an SNR can be specified.

\subsubsection{Complex exponential}
The complex exponential source is the complex equivalent of the sinusoidal source. The generated complex signal is the sum of complex exponentials with different frequencies. Optionally an SNR can be specified.

\subsubsection{Rectangular source}
The rectangular source generates a signal with multiple rectangles in the spectrum with specified frequencies and widths. The time domain signal is generated by adding multiple sinc functions with a carrier frequency. Optionally an SNR can be specified.

\subsubsection{File source}
The file source reads the samples from a file. This was used to test with real world data, but still get reproducible results. The files are compatible with \lib{GNU Radio's} file sink. The file source loops over the entire data.

\subsection{USRP N210 source}
The USRP source uses the \func{finite\_acquisition} function from the \lib{GnuRadio} package. This provides a very easy way to get a specified number of samples from one USRP. This method has a few drawbacks (see \cref{sec:drivers}). The problems with the DC compensation of the local oscillator are prevented by shifting the local oscillator out of the sampled spectrum. Unfortunately this halves our effective bandwidth. A function is also implemented which allows us to change the center frequency and the gain.

\section{Sampling}
\label{sec:sampling}
After the uniform samples are generated, different sampling methods have to be applied. Each sampler implements an interface called \func{Sampler}, which has a contract for sample-method. The interface also defines a getter for the C-matrix\footnote{This is required for the reconstructors as their algorithms require knowledge about the sample intervals.}.

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{./figures/classes_sampling.eps}
    \caption{The UML diagram of the samplers}
    \label{fig:umlclasses}
\end{figure}

\subsection{Multi-coset sampler}
\label{sub:multi_coset_sampler}
Multi-coset sampling (as introduced in \cref{cha:sampling,cha:sampling_methods}) is based on a multiple device sampler. The crucial component here is the offset of the common sampling period (sometimes referred to as the `ruler' of a multi-coset system in context of the minimal sparse ruler problem). The list of offsets is one of the constructor arguments used to generate the $C$-matrix which has dimensions defined by $M$ and $N$, which are the other arguments of this implementation.

The implementation of the sample method takes a signal, uniformly sampled, as its argument and returns a multi-coset sampled signal. Our initial implementation used a loop and a matrix multiplication. To speed up this function the for loop was vectorised by a single matrix multiplication. This is achieved by reshaping the input signal to a matrix with one dimension $N$ and the other determined by the length of the input signal.

\subsection{Minimal sparse ruler sampler}
\label{sec:multi-coset-sampler}
The minimal sparse ruler inherits from the multi-coset sampler. It feeds a solution to the minimal sparse ruler to the multi-coset sampler, which it obtains from a lookup table. It inherits all the other functionality from the multi-coset sampler.

\subsection{Coprime sampler}
\label{sec:coprime-sampler}
The coprime sampler also inherits from the multi-coset sampler. It generates a number of coprime multiples (see \cref{sec:coprime}) as a set of intervals and feeds that into the multi-coset sampler. It inherits all the other functions from the multi-coset sampler.

\section{Reconstruction}
\label{sec:reconstruction}
Two different kind of reconstruction methods are implemented. One is similar to the one specified in \cite{ariananda2012compressive} and the other is discussed in \cref{prt:theory} of this thesis. Both reconstructors implement the interface \class{Reconstructor}, which has a contract for a reconstruct method, which is depicted by the UML-diagram in \cref{fig:umlreconstructor}.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\linewidth]{./figures/classes_reconstruction.eps}
    \caption{The UML diagram of the reconstructors}
    \label{fig:umlreconstructor}
\end{figure}

Both classes make use of shared functionality to calculate a pseudo-inverse. This is a wrapper around \lib{SciPy}'s \func{pinv}. Because this operation is quite time-consuming for larger matrices, a caching mechanism was introduced to lower start-up times.

\subsection{CrossCorrelation}
\label{sub:crosscorrelation}
This class implements an algorithm based on the one described in \cite{ariananda2012compressive}. The algorithm has two parameters. The first one determines the maximum lag that will be estimated of cross-correlation of the cosets, often referred to as $L$. The second one is the sampling matrix used by the sampler described in \cref{sec:sampling}. These are also the parameters specified\footnote{\label{fn:reconparam}There are actually four parameters: $L$, $N$, $M$ and $C$. However, $N$ and $M$ can be determined from the shape of $C$.} in the paper.

Optionally a switch can be passed to disable the caching mechanism described in the base class. During the initialisation of the class it builds the $R$-matrix as discussed in \cite{ariananda2012compressive} and computes its pseudo-inverse. This was implemented for debugging and testing purposes.

The reconstruct method is implemented by calculating the cross correlations of the non-uniformly sampled input signal. A helper function is defined in the \\\func{Reconstructor} interface that calculates the cross correlations of the input. To speed up this function the multiple correlations are vectorised into a number of matrix multiplications. The pseudo-inverse is then multiplied by these cross-correlations to reconstruct the signal.

\subsection{Wessel}
\label{sub:wessel}
The reconstructor, as reformulated by Wessel Bruinsma, is a variation on the reconstruction technique implemented by \class{CrossCorrelation}. The theory is thoroughly described in \cref{prt:theory} of this thesis. The algorithm takes the same parameters\footnoteref{fn:reconparam}, namely the maximum lag estimated of the cross-correlation of the cosets and the sampling matrix used by the non-uniform sampler. This is required for the reconstruction algorithm.

Similar to the other reconstructor implementation, a switch to disable the caching mechanism has been implemented. This was also implemented for debugging and testing purposes. Like the other reconstructor, this reconstructor generates an $R$-matrix and computes its pseudo-inverse. Details on this algorithm may be found in \cref{cha:reconstruction}.

The reconstruct method is implemented by calculating the cross correlations (again) of the non-uniformly sampled input and multiplying it with the pseudo-inverse.

From an implementation perspective, the structure of the pseudo-inverse of the Wessel algorithm maps better on the data structures of \lib{NumPy}. \lib{NumPy}'s basic array data structures are in row-major order\footnote{This is the standard way of saving an array in C, two notable exceptions that save their arrays in column major order are \matlab{} and Fortran. Column major order is often called Fortran style.}. The final phase of both reconstruction steps is reshaping the cross-correlation matrix to a single column vector and multiplying it with the pseudo-inverse. This operation is more memory efficient in the Wessel reconstructor.

\section{Detection}
\label{sec:detection}
A single kind of detector is implemented. The Strategy pattern is still used because of possible future additions. All detectors have to implement the interface \func{Detector}, which has a contract for a detect method.

\subsection{Ariananda}
\label{sub:ariananda}
The Ariananda detector (named after the writer of \cite{ariananda2012compressive}) implements the theory described in \cref{cha:detection}. It takes $L$, $K$, $C$, $\mat{R}^\dagger$, $\mat{R}_c$, window length and $P_{\text{fa}}$ as its parameters. Its current implementation requires its input data to be originating from the\func{Wessel} reconstructor class\footnote{It can also be implemented for \func{CrossCorrelation} but requires some adjustments. This has not been implemented.}.

It implements the detect method by calculating a threshold (referred to as $\gamma_k$ in the theory) and comparing that with the PSD of the signal. It makes use of information of the wessel reconstructor and the sampler in question to make a better estimate of a threshold for the signal.

\begin{figure}
    \centering
    \includegraphics[width=0.3\linewidth]{./figures/classes_detection.eps}
    \caption{The UML diagram of the detectors}
    \label{fig:umldetector}
\end{figure}

\end{document}
