%!TEX program = xelatex

\documentclass[a4paper, openany, oneside]{memoir}
\input{../../../includes/preamble.tex}
\addbibresource{../../../includes/bibliography.bib}

\title{Compressive Sensing - An Overview}

\author{W.P. Bruinsma \and R.P. Hes \and H.J.C. Kroep \and T.C. Leliveld \and W.M. Melching \and T.A. aan de Wiel}

\raggedbottom

\begin{document}
\chapter{Performance}
\label{cha:performance}
In this chapter the performance of the implementation will be discussed. First we will introduce the measurements done to evaluate said performance and then we will discuss some practical implementations of these optimalisations.

\section{Profiling}
\label{sec:performance-profiling}
A good measurement technique for performance are profiling reports. Profiling reports describe the time spent inside functions. These allow us to identify bottlenecks in the system which slow down calculations. More then often these have allowed us to make crucial speed ups in the system.

\section{Algorithms and Data structures}
Our initial step was to improve the algorithms and data structures involved. This is usually seen as the first best way of improving performance. We used profiling reports as a guideline to identify bottlenecks and improve the algorithms or data structures only there were necessary as to keep the complexity of our code low\footnote{As Donald Knuth once said: ``The root of all evil is premature optimization''. The essence of this quote is that one should only start optimizing code once it has been proven to be necessary as this usually increases the complexity of the code and thus the maintainability. Maintainability is often only an afterthought but imminent for code that has to last.}.

\subsection{Sparse matrices}
\label{sec:sparse-matrices}
After the initial profiling reports it became clear that the dot product with the pseudo-inverse in the reconstructor formed a bottleneck. After doing some inspection it appeared that his matrix was sparse. The sparsity fitted good into \lib{SciPy's} sparse data structure. We chose for the rather standard \func{csr\_matrix}. As noted by \cite{scipy} the advantages of this data structure are amongst other fast matrix vector products.

\subsection{Vectorisation}
\label{sec:vectorisation}
Another way we were able to achieve a higher speed is to vectorize a number of correlations. Namely the signal cross-correlations are considerably faster when written out as a matrix multiplication. This allows us to use \lib{NumPy's} speed.

\section{Multiprocessing}
\label{sec:multiprocessing}

\subsection{GIL}
\label{sec:gil}

\subsection{Multi-core}
\label{sec:multi-core}
Each major part of the model (source, sampling, reconstruction and detection) can be run simultaneously by means of implementing a pipeline. This is done by the means of multiprocessing. We spawn a separate process for each part and pass the information around using inter-process communication. This introduces some overhead and delay because of the IPC but has the major advantage of allowing us to make use of more cores on the CPU.

\section{Results \& Improvements}
\label{sec:results}


\end{document}
