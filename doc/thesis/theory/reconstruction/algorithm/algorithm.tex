%!TEX program = xelatex

\documentclass[a4paper, openany, oneside]{memoir}
\input{../../../../includes/preamble.tex}
\addbibresource{../../../../includes/bibliography.bib}

\begin{document}


\section{Algorithm}
\label{sec:reconstruction-algorithm}
This section will discuss the algorithm to estimate in real-time the power spectral density of a signal which is sampled at sub-Nyquist frequencies. We consider multi-coset sampling such as described in \cref{cha:sampling}. A step-by-step derivation of the algorithm can be found in \cref{sec:reconstruction-derivation}.

Let the input signal sampled at the Nyquist-frequency be denoted by $x[n]$. Let the number of cosets be given by $M$. Every coset $i$ samples the input signal every $N$ samples, which means that the output of a coset is an $N$-decimation of the input signal. Let the output of coset $i$ be denoted by $y_i[n]$. Our reconstruction method estimates the power spectral density of $x[n]$ by making use of the outputs of all cosets. The Wiener-Khinchin theorem shows that estimating the power spectral density of $x[n]$ is equivalent to estimating the autocorrelation of $x[n]$.\footnote{More specifically, the Wiener-Khinchin theorem states that the Fourier transform of the autocorrelation equals the power spectral density, which yields the equivalence.} Therefore, our reconstruction method aims to estimate the autocorrelation of $x[n]$. Let the autocorrelation of the input signal be denoted by $r_x[m]$. Let the cross-correlation of the output of cosets $i$ and $j$ be denoted by $r_{y_i,y_j}[m]$. We will make use of $r_{y_i,y_j}[m]$ to estimate $r_x[m]$. This estimation is based on the relationship
\begin{align*}
    \vec{r}_{y} = \mat{R} \vec{r}_x.
\end{align*}
Here $\vec{r}_y$ represents an aggregation of $r_{y_i,y_j}[m]$ and $\vec{r}_x$ represents an aggregation of $r_x$. We see that we can use $\mat{R}$ to relate $r_x[m]$ to $r_{y_i,y_j}[m]$.

It is clear that $y_i[n]$ is part of the input of the algorithm. The way all cosets sample the input signal is determined by the sampling method. The configuration refers to the way all cosets sample the input signal. Possible configurations are discussed in \ref{cha:sampling} and will be further discussed in \ref{cha:sampling_methods}. Furthermore, the input of the algorithm also consists of the parameters $M$, $N$, $L$ and $K$. Here $M$ and $N$ have already been discussed. The parameter $L$ limits $r_{y_i,y_j}[m]$ in support from $m=-L$ to $m=L$.\footnote{If $r_{y_i,y_j}[m]$ is limited in support from $m=-L$ to $m=L$, then this means that $r_{y_i,y_j}[m]=0$ for $|m|>L$.} This influences the length of the estimated autocorrelation, which then determines the resolution of the estimated power spectral density of $x[n]$. The autocorrelation $r_x[m]$ will be estimated for $|m| \le LN$. The parameter $K$ influences the measurement time, which determines the accuracy of the estimated power spectral density. The measurement time consists of the time required to obtain $KL$ samples of the output of every coset. The inputs and output of the algorithm are summarised in Table \ref{tab:reconstruction-algorithm-inputs-outputs}. The algorithm consists of several steps.

\begin{table}
    \centering
    \begin{tabularx}{\textwidth}{llY}
        \textbf{Type} & \textbf{Parameter} & \textbf{Description} \\ \hline
        Input & $M$ & Number of cosets \\
        Input & $N$ & Downsampling factor. Every coset samples the input signal once per $N$ samples. \\
        Input & $y_i[n]$ & Output of coset $i$ \\
        Input & $L$ & Support of $r_{y_i,y_j}[m]$. This parameter influences the resolution of the estimated power spectral density of $x[n]$. \\
        Input & $K$ & Oversampling factor. This parameter influences the accuracy of the estimated power spectral density of $x[n]$, but increases the measurement time. The measurement time consists of the time required to obtain $KL$ samples of the output of every coset. \\
        Output & $r_x[m]$ & Autocorrelation of $x[n]$. The autocorrelation $r_x[m]$ is estimated for $|m| \le LN$.
    \end{tabularx}
    \caption{Input and outputs of the reconstruction algorithm}
    \label{tab:reconstruction-algorithm-inputs-outputs}
\end{table}

\begin{tabularx}{\textwidth}{rY}
    Step 1: & Determine $c_i[n]$ for every coset $i$.
    \newline \newline
    The configuration determines $c_i[n]$, which is called the sampling signal, for every coset $i$. How $c_i[n]$ can be obtained from the configuration is explained in \cref{sub:ci-circ,sub:ci-collab,sub:ci-coprime}. The restrictions on $c_i[n]$ are discussed in \cref{sub:reconstruction-ci}.
    \newline \\
    Step 2: & Construct $\mat{R}$.
    \newline \newline
    \cref{sub:reconstruction-generation} explains how to construct $\mat{R}$.
    \newline \\
    Step 3: & Measure $y_i[n]$ for $KL$ samples for every coset $i$. \newline \\
    Step 4: & Estimate $r_{y_i,y_j}[m]$ for every combination of cosets $i$ and $j$.
    \newline \newline
    \cref{sub:reconstruction-estimation} discusses how $KL$ samples of $y_i[n]$ can be used to estimate $r_{y_i,y_j}[m]$.
    \newline \\
    Step 5: & Construct $\vec{r}_y$.
    \newline \newline
    If
    \begin{align*}
        \vec{r}_{y_i,y_j} = \begin{bmatrix}
            r_{y_i,y_j}[L] \; \cdots \; r_{y_i,y_j}[-L]
        \end{bmatrix},
    \end{align*}
    then
    \begin{align*}
        \vec{r}_y = \begin{bmatrix}
            \vec{r}_{y_1,y_1} \\ \vdots \\ \vec{r}_{y_M,y_M}
        \end{bmatrix}.
    \end{align*}
    \newline \\
    % Step 6: &  Solve \cref{eq:normal-rx} to estimate $\vec{r}_x$, which yields an estimation of $r_x[m]$.
    % \newline \newline
    % The vector  $\vec{r}_x$ is defined in \cref{eq:def-rx}. Once more, \cref{eq:normal-rx} will be discussed in the derivation of the algorithm.
    % \newline \\
    Step 6 : & Calculate $\vec{r}_x=\mat{R}^\dagger \vec{r}_y$, which yields an estimation of $r_x[m]$.
    \newline \newline
    Here
    \begin{align*}
         \vec{r}_x = \begin{bmatrix}
             r_x[LN] \; \cdots \; r_x[-LN]
         \end{bmatrix}.
    \end{align*} Therefore the autocorrelation $r_x[m]$ is estimated for $|m| \le LN$. The matrix $\mat{R}^\dagger$ denotes the Moore-Penrose pseudoinverse of $\mat{R}$.
\end{tabularx}

\end{document}