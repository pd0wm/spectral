% \subsection{Explanation}
% Let $L$ samples of the signal $x[n]$ be collected in the vector $\vec{x} = \left[x[n], x[n+1], \ldots, x[n+L]\right]^T$. 
% Furthermore let $\mat{C} = E\left(\left(\vec{x} - \mu \right)\left(\vec{x} - \mu \right)^H\right)$ denote the covariance of $\vec{x}$ with $\mu = E(\vec{x})$.

% In the case that $E\left(\vec{x}\right)=0$, like for noise or most communication signals, then $\mat{C}$ can be simplified to

% \begin{align*}
% \mat{C}_x &= E\left(\vec{x}\vec{x}^T\right) \\
% &= \begin{bmatrix} 
% E\left(x[n][n]\right) & E\left(x[n][n+1]\right) & \ldots & E\left(x[n][n+L-1]\right) \\
% E\left(x[n+1][n]\right) & E\left(x[n+1][n+1]\right) & \ldots & E\left(x[n+1][n+L-1]\right) \\
% \vdots & \vdots & \ddots & \vdots \\
% E\left(x[n+L-1][n]\right) & E\left(x[n+L-1][n+1]\right) & \ldots & E\left(x[n+L-1][n+L-1]\right) \\
% \end{bmatrix}.
% \end{align*}
% Under the assumption that $x[n]$ is a wide-sense stationary signal, we can simplify $\mat{C}$ even further:
% \begin{align*}
% \mat{C}&= E\left[\vec{x}\vec{x}^T\right] \\
% &= \begin{bmatrix} 
% r_x[0] & r_x[1] & \ldots & r_x[L-1] \\
% r_x[1] & r_x[0] & \ldots & r_x[L-2] \\
% \vdots & \vdots & \ddots & \vdots \\
% r_x[L-1] & r_x[L-2] & \ldots & r_x[0] \\
% \end{bmatrix}.
% \end{align*}
% Note how $\mat{C}$ is symmetric and Toeplitz: this is the first block in \cref{tkz:cav}. As  the autocorrelation function of white noise is a delta function, it means that  if $x[n]$ is white noise with variance $\sigma_n^2$ then $\mat{C}_x = \sigma_n^2\mat{I}$.
% If the signal $x[n]$ is not equal to noise, then its autocorrelation function is not equal to a delta function which results in $\mat{C}$ having non-zero off diagonal elements.

% Covariance absolute value method detection uses a measure of this ``diagonality'' of $\mat{C}$ as test statistic $\Lambda$.
% This measure $\Lambda$ is defined as
% \begin{align}\label{eq:cav_statistic}
% \Lambda &= \frac{T_1}{T_2} \nonumber \\
% &=\frac{\sum_{n=1}^{L} \sum_{m=1}^L \left|\mat{C}_{nm}\right|}{\sum_{k=1}^L |\mat{C}_{kk}}
% \end{align} 

% with $T_1 = \frac{\sum_{n=1}^{L} \sum_{m=1}^L \left|\mat{C}_{nm}\right|}{L}$ and
% $T_2 = \frac{\sum_{k=1}^L |\mat{C}_{kk}}{L}$.
% This test statistic can be computed by first taking the absolute value of $\mat{C}$. This is then followed by summing all the elements of the resulting matrix (forming the numerator in \cref{eq:cav_statistic}) and computing the trace (the denominator in \cref{tkz:conv_ed}) of that matrix. Upon diving those two results one obtains the test statistic $\Lambda$. This process is depicted in \cref{tkz:cav}.

% In practice one estimates the matrix $\mat{C}$ by using a limited amount of samples $N$ to estimate $r_x[n]$. The threshold given a desired false alarm probability
% $p_{fa}$ is derived in \cite{zheng2009spectrum} to be

% \begin{align*}
% \gamma &= \frac{\left(1+(L-1)\sqrt{\frac{2}{N\pi}}\right)}{1-Q^{-1}(p_{fa})\sqrt{\frac{2}{N}}}.
% \end{align*} 

% As with the conventional energy detector, it is not trivial how the reconstructor influences the parameter $N$ .

% \subsection{Adjusting the threshold}

% In \cite{zheng2009spectrum} it is assumed that for large $N$ the distribution of $T_1$ and $T_2$ approach gaussian distributions. Given a fixed false alarm probability, the threshold $\gamma$ is derived under the hypothesis $\mathcal{H}_0$. The following should hold

% \begin{align*}
% p_{fa} &\approx P\left(\frac{T_1}{T_2} > \gamma \big | \mathcal{H}_0\right) \\
% &= P\left(T_2 < \frac{T_1}{\gamma} \big | \mathcal{H}_0\right)
% \end{align*}

% Under $\mathcal{H}_0$, the distribution of $T_2 = r_x[0]$ is approximated by a gaussian. We can therefore derive the
% threshold $\gamma$ by noting that.

% \begin{align*}
% p_{fa} &= P\left(\frac{\frac{E\left(T_1\right)}{\gamma} - E\left(T_2\right) }{\sqrt{\text{Var}(T_2)}}\right)\\
% &= 1-Q\left(\frac{\frac{E\left(T_1\right)}{\gamma} - E\left(T_2\right) }{\sqrt{\text{Var}(T_2)}}\right) 
% \end{align*}

% To solve for $\gamma$ we have to determine $E\left(T_1\right)$, $E\left(T_2\right)$ and $\Var(T_2)$. It is at this point that we cannot use the expressions from \cite{zheng2009spectrum} as they assume that $r_x[m]$ is estimated by the sample autocorrelation function. 

% Let $\vec{\hat{r}_x} = \left[\hat{r}_x[-LN], \hat{r}_x[-LN+1] , \ldots, \hat{r}_x[LN]\right]$ denote the vector containing the, by the reconstructor, estimated elements of $r_x[m]$. Then 

% \begin{align*}
% E(\vec{\hat{r}}_x) &= \mat{R}^{\dagger}E(\vec{r}_y)
% \end{align*}

% contains $r_x[m]$ for $-LN \leq m \leq LN$. Notice that this vector contains $r_x[0] = E(T_2)$ and can be used to construct $E(\mat{C})$ (and therefore can be used to determine $E(T_1)$).

% To obtain $\Var(r_x[0])$ we notice that the $\Var(r_x[m])$ is contained (for $-LN \leq m \leq LN$) on the diagonal of the covariance matrix of $\vec{\hat{r}_x}$, which is denoted by $\mat{C}_{\hat{r}_x}$.

% This covariance matrix is equal to
% \begin{align*}
% \mat{C}_{\hat{r}_x} &= E(\vec{\hat{r}}_x\vec{\hat{r}}_x^T) - E(\vec{\hat{r}}_x) E(\vec{\hat{r}}_x^T)\\
% &= R^{\dagger}C_{\hat{r}_y}(R^{\dagger})^H.
% \end{align*}

% The elements of the covariance matrix $C_{\hat{r}_y}$ are derived in \cite{ariananda2012compressive} to equal:

% \begin{align}
% \Cov(r_{{y_i},y_j}, r_{{y_w},y_v}) &= \frac{\sigma_n^4} r_{c_i,c_w}[0]\overline{r}_{c_j,c_v}[0]\delta[q-k].
% \end{align}

% The threshold $\gamma$ can then be calculated as

% \begin{align*}
% \gamma &= \frac{E(T_1)}{Q^{-1}(1-p_{fa})\sqrt{\Var(T_2)}+E(T_2)}
% \end{align*}
