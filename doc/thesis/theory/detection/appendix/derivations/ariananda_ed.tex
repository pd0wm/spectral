%!TEX program = xelatex

\documentclass[a4paper, openany, oneside]{memoir}
\input{../../../../../includes/preamble.tex}
\addbibresource{../../../../../includes/bibliography.bib}

\begin{document}

\section{Energy detector using the reconstructed autocorrelation}\label{sec:ari_ed_deriv}
In this section we will derive how $\gamma_k$ as introduced in \cref{ssec:ari_ed} can be calculated. This derivation is largely based on \cite{ariananda2012compressive}.

We assume that if our signal $x[n]$ purely contains noise, then $x[n] \sim \mathcal{CN}(0,\sigma_n)$. Let $\vec{\hat{r}}_x = [\hat{r}[-LN], \ldots, \hat{r}[0], \ldots \hat{r}[LN]]^T$ denote the vector containing the estimated elements of the autocorrelation. 
By ??? we know that $\vec{\hat{r}}_x$ is given as
\begin{align*}
\vec{hat{r}}_x &= \mat{R}^{\dagger}\vec{r}_y.
\end{align*}.
Furthermore let $(\vec{\hat{s}}_x) = \mat{F} \vec{\hat{r}}_x$, where $\mat{F}$ denotes the $2LN-1 \times 2LN-1$ DFT matrix. Then $\vec{s}_x$ contains an estimate of the power spectral density.
In \cite{ariananda2012compressive} it is derived that when $KLN$ is large, then the elements of $\vec{s}_x$ are approximately gaussian distributed, which we will denote as $\hat{r}_x[m] \sim \mathcal{N}(\mu_m,\sigma^2_m$ with $-LN \leq m \leq LN$.

By noting that

If $\mat{C}_{s_x}$ denotes the covariance matrix of $\vec{s}_x$, then the variance of a element of $\vec{s}_x$ can be found on its diagonal.
Using the relation for $\vec{s}_x$, we can compute the covariance matrix $\mat{C}_{s_x}$ as:

\begin{align*}
\mat{C}_{s_x} &= E\left[\vec{s}_x\vec{s}_x^H\right] - E\left[\vec{s}\right]E\left[\vec{s}^H\right] \\
&= E\left[\left(\mat{F} \mat{R}^{\dagger}\vec{r}_y\right) \left( \mat{F}\mat{R}^{\dagger}\vec{r}_y\right)^H\right] - E\left[\mat{F}\mat{R}^{\dagger}\vec{r}_y\right]E\left[\left(\mat{F}\mat{R}^{\dagger}\vec{r}_y\right)^H\right] \\
&= \mat{F}\mat{R}^{\dagger} E\left[ \vec{r}_y\vec{r}_y^H\right]  \mat{R}^{\dagger H}\mat{F}^H -  \mat{F}\mat{R}^{\dagger} E\left[ \vec{r}_y\right] E\left[\vec{r}_y^H\right]   \mat{R}^{\dagger H}\mat{F}^H \\
&= \mat{F}\mat{R}^{\dagger} \mat{C}_{r_y} \mat{R}^{\dagger H}\mat{F}^H
\end{align*}

Let $\mat{C}_{r_y}$ denote the covariance matrix of of $\vec{r}_y$, with its elements given by

\begin{align}\label{eq:cov_ry}
(\mat{C}_{r_y})_{i,j} &= \text{Cov}(\vec{r_{y_t,y_u}}_i,\vec{r_{y_v, y_w}}_j).
\end{align}

As stated in \cite{ariananda2012compressive}, under the assumption that the elements of $\vec{x}$ are i.i.d. circular complex gaussian distributed, the expression for the covariance in \cref{eq:cov_ry} simplifies to:

\begin{align*}
\text{Cov}(\vec{r_{y_t,y_u}}_i,\vec{r_{y_v, y_w}}_j) &= \frac{\sigma_n^4 \vec{r_{c_t,c_v}}_N \vec{\overline{r}_{c_u,c_w}}_N \delta \left[ j-i\right]}{d}
\end{align*}.

<<<<<<< HEAD
As $\vec{c}_i$ and $\vec{c}_j$ are constant vectors, we will only have to focus on the last term. Let us introduce the helper variable $a =  \sum_{k=1}^{KL} (\vec{x})_{kN-l+1} \cdot (\vec{\overline{x}})_{(k-u+L)N - m+1}$. Notice that if

\begin{enumerate}
	\item $u=L, l=m$, then $a = \sum_{k=1}^{KL}\vec{x}_{kN-l+1}\vec{\overline{x}}_{kN-l+1}$. That is, $a$ follows a $\chi^2$ distribution (by definition). As with the convential energy detector, we can approximate the distribution of the sum as a whole as gaussian if $KL$ is large enough.
	\item $l \neq m$. Notice that as 
	% \begin{align*}\{(\vec{x})_{kN-l+1} : 1 \leq k \leq KL\} \cap 
	% \{(\vec{x})_{(k-u+L)N - m+1} : 1 \leq k \leq KL\}  &= \emptyset
	% \end{align*}

	\begin{align*}
	\bmod(kN-l+1,N) &= \bmod(-l+1, N)
	\end{align*}
	and
	\begin{align*}
	\bmod((k-u+L)N - m+1,N) &= \bmod(-m+1, N)
	\end{align*}
	the product in the sum
	That is $(\vec{x})_{kN-l+1}$  can never equal  $(\vec{x})_{(k-u+L)N - m+1}$ in $a$. Because each element of $\vec{x}$ has the same distribution, the product of two distinct elements in $\vec{x}$ will always yield the same distribution (whatever it may be). By the Central Limit Theorem we can approximate the distribution of the sum as a whole as gaussian if $KL$ is large enough.

	\item $u\neq L, l=m$ In this case, the product in the sum contains elements of $\vec{x}$ with a minimum displacement of $N$ in their indices. Unlike case 2, the specified sets \emph{can} have elements in common. To see why, consider \cref{fig:ex_dep}. Notice, that the dependence of a product in the sum on other products is limited: for each element of $\vec{x}$ there will be a maximum of two terms in $a$ dependent on that element. Notice that as $u\neq L$ the first $L-u$ multiplicands in $a$ can \emph{never} appear as multiplier in $a$. The first $L-u$ multipliers, however \emph{can} appear as multiplicand in $a$.  Using this observation we rewrite $a$ using two sums, which alternatingly sum $L-u$ consecutive terms (which guarantees that the multiplicands in the sum can never equal the multiplier) of the original sum in $a$: 

	\begin{align*}
	a &= \sum_{q=1}^{\left\lfloor{\frac{KL}{2(L-u)}}\right\rfloor} \sum_{r=1}^{L-u} \vec{x}_{((2q-1)(L-u)+r)N-l+1}\vec{\overline{x}}_{((2q-1)(L-u)+r)N-l+1} \\
	   & \;+ \sum_{s=1}^{\left\lfloor{\frac{KL}{2(L-u)}}\right\rfloor} \sum_{t=1}^{L-u} \vec{x}_{(2s(L-u)+t)N-l+1}\vec{\overline{x}}_{(2s(L-u)+t)N-l+1}
	\end{align*}
	Note that we tacitly assumed that $L-u \geq 0$. This does not pose a problem as similar analysis for $L-u < 0$ is possible. 
	Therefore, if $\left\lfloor{\frac{KL}{2(L-u)}}\right\rfloor$ is large enough, $a$ is the sum of two approximately gaussian distributed variables, and therefore itself is approximately gaussian distributed.			
\end{enumerate}

\begin{figure}
\begin{tikzpicture}
\node (species1) {
\begin{tabular}{|c|c|c|c|c|c|c|c|}\hline
    $(\vec{x})_{2N-l+1}$ & $\ldots$  & $(\vec{x})_{3N-l+1}$ & $\ldots$ & $(\vec{x})_{4N-l+1}$ & $\ldots$ & $(\vec{x})_{5N-l+1}$  & $\ldots$ \\ \hline 
    \end{tabular}
  
};
\node (species2) [below right= 0.2cm and -14.5cm of species1] {
      \begin{tabular}{|c|c|c|c|c|c|c|c|}\hline
    $(\vec{x})_{N-l+1}$ & $\ldots$  & $(\vec{x})_{2N-l+1}$ & $\ldots$ & $(\vec{x})_{3N-l+1}$ & $\ldots$ & $(\vec{x})_{4N-l+1}$  & $\ldots$ \\ \hline 
    \end{tabular}
};
\end{tikzpicture}
\caption{Example illustrating dependence, $u=L-1$}
\label{fig:ex_dep}
\end{figure}
=======
Now that we have analyzed how to compute the variance of each element of $\vec{s}_x$, we will analyze the expression of their expected value ($\mu$).
>>>>>>> ce205588a6e12dc5693c1b9458a8c72e17f44173

\begin{align*}
E\left[\vec{s}_x\right] &= \mat{F}\mat{R}^{\dagger}E\left[\vec{r}_y\right] 
\end{align*}.

The elements of $(\vec{r}_y$ are given by 
\begin{align*}
\vec{r}_{y_i, y_j}[k] &= \vec{r}_{c_i,c_j} \ast \vec{r}_x & \text{\cref{th:convolution-correlation}} \\
&=  \left( \vec{r}_{c_i,c_j}\right)_N  \vec{\delta}_N
\end{align*}

Now that we both know the variance and mean of each element, we obtain that our threshold $\gamma_{\omega}$ given a false alarm probability $p_{fa}$:

\begin{align*}
Q^{-1}(p_{fa})\sigma_{\omega} + \mu_{\omega}
\end{align*}

This concludes the main analysis.

\end{document}